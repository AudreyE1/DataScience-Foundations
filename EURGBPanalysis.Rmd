---
title: "Analysis of the EUR/GBP  currency pair"
author: "Audrey Ekuban"
date: "28 May 2016"
output: word_document
---

The euro British pound (EUR/GBP, EURGBP) is a currency pairing whereby the euro and the pound are traded against each other. You short (sell) the euro and go long (buy) the pound or go long (buy) the euro and short (sell) the pound. The EUR/GBP is one of the most traded currency pairs and also, one of the most stable (though that may change). EUR is the base currency. So EURGBP = 0.8 means that 1 EUR is exchanged for 0.8 GBP. If the EURGBP rises to 0.85 then GBP is weakening against EUR.


# Types Of Analysis Used In Forex

Forex analysis is used to determine whether to buy or sell a currency pair at any one time. Forex analysis could be technical in nature, using charting tools, or fundamental in nature, using economic indicators and/or news based events. A trader's currency trading system use analysis that create buy or sell decisions when they point in the same direction.


## Fundamental Analysis

Fundamental analysis is often used to analyze changes in the forex market by monitoring factors, such as interest rates, unemployment rates, gross domestic product (GDP) and many other economic releases that come out of the countries in question. For example, a trader analyzing the EUR/GBP currency pair fundamentally, would be interested in how a Brexit decision would impact interest rates in the UK. They would also want to be on top of any significant news releases which could indicate that a Brexit decision is likely.

## Technical Analysis

Technical analysis is a method of evaluating securities by analyzing statistics generated by market activity, such as past prices and volume. Technical analysts do not attempt to measure a security's intrinsic value, but instead use charts and other tools to identify patterns that can suggest future activity.

The field of technical analysis is based on three assumptions: 

1. The market discounts everything. 
2. Price moves in trends. 
3. History tends to repeat itself. 

A technical indicator is a method of chart analysis, usually of price over time or volume, using various formulae designed to highlight specific characteristics and provide signals to help forecast market movements. Indicators can also be derived from the use of trendlines and price patterns, which are not based on formulae and are more subjective.

### Time Series Analysis

Time Series analysis has two main goals: Identifying the nature of a sequence of observations and predicting future values using historical observations (forecasting). In time series analysis it is assumed that the data consists of a systematic pattern and random noise which usually makes the pattern difficult to identify. Most time series analysis techniques use filtering to remove noise.

There are two general components of Time series patterns: Trend and Seasonality. The trend is a linear or non-linear component and it does not repeat within the time range. The Seasonality repeats itself in systematic intervals over time. 

Trend analysis is a technique used to identify a trend component in the time series data. In many cases data can be approximated by a linear function, but logarithmic, exponential and polynomial functions can also be used.

Regression Analysis, used in trend analysis, is the study of relationships among variables, and its purpose is to predict or estimate the value of one variable from known values of other variables related to it. Any method of fitting equations to data may be called regression, and these equations are useful for making predictions and judging the strength of relationships.

Forecasting and extrapolation from present values to the future values is not a function of regression analysis. To predict the future time series analysis is used.

The least-squares method is the most common predictive function, and it calculates the minimum average squared deviations between the points and the estimated function. However maximimising Log-Likelihoods and minimising AIcc (Akaike information criterion) are also used.


# Analysis Steps

## Step 1 - Download the data 

I downloaded currency data from www.forexite.com.The website provides free intraday data for 16 currencies. The data goes back to 2001. The R script below was used to download and unzip the data files.

```{r eval=FALSE}
# Download currency data from forexite.com

getFiles <- function(URL) {
  zipfile = unlist(strsplit(URL, "/")[[1]])[7]
  txtfile = replace(zipfile, '.zip', '.txt')
  download.file(URL, zipfile)
  data <- read.table(unzip(zipfile))
}

#setwd("RawData")

# Download all data that exists between 3rd January 2001 and 14th May 2016 inclusive
downloadDates = format(seq(as.Date("2001/01/03"), as.Date("2016/05/14"), "days"), 
                       format="%Y/%m/%d%m%y")
# Set download URL
downloadURL = paste('http://www.forexite.com/free_forex_quotes/', downloadDates, '.zip', sep='')

# Start Download
for (i in downloadURL) {
  print(i)
  tryCatch({
    getFiles(i)
  }, error=function(e){})
}
```

## Step 2 - Extract the EURGBP data and merge into one file

The downloaded files contain a number of currency pairs.Since I was only interested in the EUR / GBP I needed to extract the lines that started with EURGBP. I did so using the script below.

```{r eval=FALSE}
library(dplyr)

setwd("RawData")

# We are only interested in *.txt files
myFiles <- list.files(pattern = ".txt") 

# Create empty dataframe
df <- data.frame(V2 = (character()),
                 V3 = character(), 
                 V4 = character(),
                 V5 = character(),
                 V6 = character(),
                 V7 = character()
                 
) 

# Read tge data from the files into the dataframe
for (f in myFiles) {
  tryCatch({
    if (file.size(f) > 0){
      df2 = read.csv(f, skip=1, header=FALSE, colClasses=c('character'))
      df2 = filter(df2, V1 == 'EURGBP') %>% select(-V1)
      df = rbind_list(df, df2)
    }
  }, error = function(err) {
    print(paste(f, ' : ', err))
  })
}

write.table(df, '../Data/EURGBP.csv', row.names = FALSE, col.names = c('DATE', 'TIME', 'OPEN', 'HIGH', 'LOW', 'CLOSE'), quote = FALSE, sep=",")
```

## Step 3 - Data Preparation

The data in EURGBP.csv contained a separate DATE and TIMe column. The data is a weakly regular time series i.e. there was some missing data.However the missing data was due to the FOREX market being closed so in reality the data wasn't missing. Converting the data to a Time Series object in R created a strictly regular time series and this is what was used in the analysis.

The data shows that during the 2007/2008 Financial crisis GBP was at is weakest point against EUR.

```{r echo=TRUE}
setwd("Data")

#The below produces an error
#install.packages('ggfortify')

#install.packages("devtools")
#library(devtools)

#install_github('sinhrks/ggfortify')
library(ggfortify)

#install.packages('xts')
library(xts)

#install.packages('forecast')
library(forecast)

# read the data
EURGBP = read.csv("EURGBP.csv", colClasses=c(rep("character", 2), rep("numeric", 4)))
datetime <- as.POSIXct(paste(EURGBP$DATE, EURGBP$TIME), format = "%Y%m%d %H%M%OS")
EURGBP = EURGBP[c(3:6)]
summary(EURGBP)

# Make sure ordering is correct and convert to daily
EURGBP.xt <- xts(x = EURGBP, order.by = datetime)
EURGBP.xt.daily = to.daily(EURGBP.xt)

names(EURGBP.xt.daily) = c('Open', 'High', 'Low', 'Close')
head(EURGBP.xt.daily)
tail(EURGBP.xt.daily)

# Plot the multi-variate time series
pallet = c('red', 'blue', 'green', 'orange')
autoplot(EURGBP.xt.daily, ts.colour = 'variable', main = 'EURGBP prices') + scale_colour_manual(values=pallet)

# Check if data is weakly or strictly regular
is.regular(EURGBP.xt.daily)
is.regular(EURGBP.xt.daily, strict = TRUE)

# Convert data to Time Series for analysis 
EURGBP.ts.daily = ts(EURGBP.xt.daily, names=c('Open', 'High', 'Low', 'Close'))
is.regular(EURGBP.ts.daily, strict = TRUE)

head(EURGBP.ts.daily)
tail(EURGBP.ts.daily)

# Focus on closing prices
EURGBP.price = EURGBP.ts.daily[,'Close']

autoplot(as.zoo(EURGBP.price), ts.colour = 'blue') +
  ggtitle('EURGBP Closing Prices') + xlab('Time Index') + ylab('price')

# Split the time series into Training and Testing
EURGBP.training = window(EURGBP.price, 1, 3000)
EURGBP.test = window(EURGBP.price, 3000)
```

## Step 4 - Plot Data and examine

A stationary time series is one whose statistical properties such as mean, variance, autocorrelation, etc. are all constant over time. The stationarized series can be prediced as the properties will be the same in the future as they have been in the past.

The Autocorrelation Function (ACF) and the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test was used to check for stationarity.

Based on the KPSS p-value stated below, the hypothesis of stationarity is rejected.In addition, the ACF plot shows a slow linear decay, indicative of a non-stationary time series. 

```{r echo=TRUE}
autoplot(as.zoo(EURGBP.training), ts.colour = 'blue') +
  ggtitle('Training Data') + xlab('Time Index') + ylab('Closing Price')

Acf(EURGBP.training)

tseries::kpss.test(EURGBP.training)

# Check - How many differences do we need to take 
ndiffs(EURGBP.training)

#The below produces an error as the data is not seasonal 
#nsdiffs(EURGBP.training)
```

## Step 5 - Transform the data and examine

Based on the KPSS p-value stated below, the hypothesthat that the time series is stationarity is rejected.In addition, the ACF plot shows a slow linear decay, indicative of a non-stationary time series. 

```{r echo=TRUE}
# Use BoxCox to transform the data
lambda = forecast::BoxCox.lambda(EURGBP.training,lower=-2)
lambda
transformedPrices = forecast::BoxCox(EURGBP.training, lambda)

# Train the data
autoplot(as.zoo(transformedPrices), ts.colour = 'blue') +
  ggtitle('Training Data') + xlab('Time Index') + ylab('transformed Closing Price')

Acf(transformedPrices)

tseries::kpss.test(transformedPrices)

# Check - How many differences do we need to take 
ndiffs(transformedPrices)

#The below produces an error as the data is not seasonal 
#nsdiffs(transformedPrices)
```

## Step 6 - Take 1st differences of the transformed data

Based on the KPSS p-value stated below, the hypothesthat that the time series is stationarity is not rejected.In addition, The ACF plot also indicates a stationary time series.

```{r echo=TRUE}
diffPrices = diff(transformedPrices)
autoplot(as.zoo(diffPrices), ts.colour = 'blue') +
  ggtitle('First Difference Training Data') + xlab('Time Index') + ylab('transformed Closing Price')

Acf(diffPrices)

tseries::kpss.test(diffPrices)

summary(diffPrices)
```

## Step 7 - Model Identification and Estimation

The Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) of the stationary series now need to be examined o estimate the ARIMA(p,d,q) model. 

It should be noted that we can use auto.arima in R to give an estimate of the model.

The d in ARIMA(p,d,q) stands for the number of times the data had to be differenced to become to stationary. In this case d = 1.

The p in ARIMA(p,d,q) measures the order of the autoregressive component. The time-series has an autoregressive order of 1, called AR(1), then we should see only the first partial autocorrelation coefficient as significant. However this is not the case

The q in ARIMA(p,d,q) is the number of lagged forecast errors in the prediction equation. This is usually referred to as the Moving Average (MA) term.

Generally, PACF will have significant correlations up to lag p, and will quickly drop to near zero values after lag p. Further work is needed.

```{r echo=TRUE}
auto.arima(transformedPrices)

pacf(diffPrices)

# Use acf rather tha Acf
acf(diffPrices)
```

### Increase lags in differenced data

The above differened data uses a lag of 1 i.e. the difference is taken of 2 consecutive data points. For a lag of 2, the differences between the third and the first value, between the fourth and the second value, between the fifth and the third value etc. are calculated. 

```{r echo=TRUE}
diffPrices = diff(transformedPrices, lag = 2, diff = 1)

pacf(diffPrices)

# Use acf rather tha Acf
acf(diffPrices)

# Increase maximum order
auto.arima(transformedPrices, approximation=FALSE, stepwise=FALSE, max.order=15)
```

The auto.arima results above indicate that ARIMA(p = 3, d = 1, q = 2) might be a best fit (it has lowest (AICc value). Try one more lag and calculate various ARIMA's to  verify that this is feasible.

```{r echo=TRUE}
diffPrices = diff(transformedPrices, lag = 3, diff = 1)

pacf(diffPrices)

# Use acf rather tha Acf
acf(diffPrices)

diffPrices = diff(transformedPrices, lag = 3, diff = 2)

pacf(diffPrices)

# Use acf rather tha Acf
acf(diffPrices)

AIC(Arima(transformedPrices, c(3,1,2)),
    Arima(transformedPrices, c(4,1,3)),
    Arima(transformedPrices, c(5,1,4)))
```

It should be noted that the plots indicate a very high-ordered model. However, it is possible for an AR term and an MA term to cancel each other's effects, even though both may appear significant in a model.

## Step 8 - Forecasting

Apply one step forecasting of the model to the Test set. The test data set is modelled extremely well and errors approximately match the errors in the Training set.

However using the model to predict if EUR value will increase or decrease would be incorrect. That is for another Capstone. But I was curious. Taking lags into consideration, it can be seen that the model will correctly predict the direction of the price in approximately 73% of cases. Not good enough to risk your cash.

```{r echo=TRUE}
testTransformedPrices = forecast::BoxCox(EURGBP.test, lambda)

# Model
transformedPrices.fit <- Arima(transformedPrices, c(3,1,2))
ggtsdiag(transformedPrices.fit)
summary(transformedPrices.fit)


# Apply model to test
testTransformedPrices.fit = Arima(testTransformedPrices, model=transformedPrices.fit)
ggtsdiag(testTransformedPrices.fit)
accuracy(fitted(testTransformedPrices.fit), testTransformedPrices)

EURGBP.transformed = cbind(testTransformedPrices, fitted(testTransformedPrices.fit))
colnames(EURGBP.transformed) = c('Actual', 'Predicted')

pallet = c('red', 'blue')
autoplot(EURGBP.transformed, ts.colour = 'variable', main = 'EURGBP prices') +
  scale_colour_manual(values=pallet) +
  xlab('Time Index') + ylab('Transformed Closing Price')


# Long Training
actualDirection = sapply(transformedPrices, function(x) diff(x, 3, 1) > 0)
predictedDirection = sapply(fitted(transformedPrices.fit), function(x) diff(x,3,1) > 0)
table(actualDirection, predictedDirection)

#Short Training
actualDirection = sapply(transformedPrices, function(x) diff(x, 3, 1) < 0)
predictedDirection = sapply(fitted(transformedPrices.fit), function(x) diff(x, 3, 1) < 0)
table(actualDirection, predictedDirection)


# Long Test
actualDirection = sapply(testTransformedPrices, function(x) diff(x, 3, 1) > 0)
predictedDirection = sapply(fitted(testTransformedPrices.fit), function(x) diff(x,3,1) > 0)
table(actualDirection, predictedDirection)

#Short Test
actualDirection = sapply(testTransformedPrices, function(x) diff(x, 3, 1) < 0)
predictedDirection = sapply(fitted(testTransformedPrices.fit), function(x) diff(x, 3, 1) < 0)
table(actualDirection, predictedDirection)
```

### Verify untransformed data

```{r echo=TRUE}
# Untransform the fitted values
fittedPrices = forecast::InvBoxCox(fitted(testTransformedPrices.fit), lambda)

EURGBP.test.prices = cbind(EURGBP.test, fittedPrices)
colnames(EURGBP.test.prices) = c('Actual', 'Predicted')

pallet = c('red', 'blue')
autoplot(EURGBP.test.prices, ts.colour = 'variable', main = 'EURGBP prices') +
  scale_colour_manual(values=pallet) +
  xlab('Time Index') + ylab('Closing Prices')
```